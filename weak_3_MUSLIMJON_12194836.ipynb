{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXyYWI9P//J1UGSQ1omwR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i9muslimbek/muslimjon/blob/main/weak_3_MUSLIMJON_12194836.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Dxmmyh87HEX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(3) # To make repeatable LEARNING_RATE = 0.1\n",
        "index_list = [0, 1, 2, 3] # Used to randomize order\n",
        "# Define training examples.\n",
        "x_train = [np.array([1.0, -1.0, -1.0]),\n",
        "np.array([1.0, 1.0, -1.0]),\n",
        "np.array([1.0, 1.0, 1.0])]\n",
        "y_train = [0.0, 1.0, 1.0, 0.0] # Output (ground truth)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron_w(input_count):\n",
        "  weights = np.zeros(input_count+1)\n",
        "  for i in range(1,(input_count+1)):\n",
        "    weights[i] = np.random.uniform(-1.0, 1.0)\n",
        "    return weights\n",
        "n_w = [neuron_w(2), neuron_w(2), neuron_w(2)] \n",
        "n_y = [0, 0, 0]\n",
        "n_error = [0, 0, 0]"
      ],
      "metadata": {
        "id": "roijbFpa7YH7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def show_learning():\n",
        "    print('Current weights:')\n",
        "    for i, w in enumerate(n_w):\n",
        "        print('neuron ', i, ': w0 =', '%5.2f' % w[0],\n",
        "              ', w1 =', '%5.2f' % w[1], ', w2 =',\n",
        "              '%5.2f' % w[2])\n",
        "    print('----------------')\n",
        "\n",
        "def forward_pass(x):\n",
        "    global n_y\n",
        "    n_y[0] = np.tanh(np.dot(n_w[0], x)) # Neuron 0\n",
        "    n_y[1] = np.tanh(np.dot(n_w[1], x)) # Neuron 1\n",
        "    n2_inputs = np.array([1.0, n_y[0], n_y[1]]) # 1.0 is bias\n",
        "    z2 = np.dot(n_w[2], n2_inputs)\n",
        "    n_y[2] = 1.0 / (1.0 + np.exp(-z2))\n",
        "\n",
        "def backward_pass(y_truth):\n",
        "    global n_error\n",
        "    error_prime = -(y_truth - n_y[2]) # Derivative of loss-func\n",
        "    derivative = n_y[2] * (1.0 - n_y[2]) # Logistic derivative\n",
        "    n_error[2] = error_prime * derivative\n",
        "    derivative = 1.0 - n_y[0]**2 # tanh derivative\n",
        "    n_error[0] = n_w[2][1] * n_error[2] * derivative\n",
        "    derivative = 1.0 - n_y[1]**2 # tanh derivative\n",
        "    n_error[1] = n_w[2][2] * n_error[2] * derivative\n",
        "\n",
        "def adjust_weights(x):\n",
        "    global n_w\n",
        "    n_w[0] -= (x * LEARNING_RATE * n_error[0])\n",
        "    n_w[1] -= (x * LEARNING_RATE * n_error[1])\n",
        "    n2_inputs = np.array([1.0, n_y[0], n_y[1]]) # 1.0 is bias\n",
        "    n_w[2] -= (n2_inputs * LEARNING_RATE * n_error[2])"
      ],
      "metadata": {
        "id": "J30_dMfC8cFX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Network training loop.\n",
        "all_correct = False\n",
        "while not all_correct: # Train until converged\n",
        "    all_correct = True\n",
        "    np.random.shuffle(index_list) # Randomize order\n",
        "    for i in index_list: # Train on all examples\n",
        "       forward_pass(x_train[i])\n",
        "       backward_pass(y_train[i])\n",
        "       adjust_weights(x_train[i])\n",
        "       show_learning() # Show updated weights\n",
        "    for i in range(len(x_train)): # Check if converged\n",
        "        forward_pass(x_train[i])\n",
        "        print('x1 =', '%4.1f' % x_train[i][1], ', x2 =',\n",
        "              '%4.1f' % x_train[i][2], ', y =',\n",
        "              '%.4f' % n_y[2])\n",
        "        if(((y_train[i] < 0.5) and (n_y[2] >= 0.5))\n",
        "                or ((y_train[i] >= 0.5) and (n_y[2] < 0.5))):\n",
        "            all_correct = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9Lyr3TSM8utA",
        "outputId": "7b4207aa-d020-43c5-82cf-a50d4f94c3a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2fcb302eb382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m        \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m        \u001b[0madjust_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m        \u001b[0mshow_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Show updated weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Check if converged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ffd5cc37a151>\u001b[0m in \u001b[0;36madjust_weights\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madjust_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m    \u001b[0;32mglobal\u001b[0m \u001b[0mn_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m    \u001b[0mn_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m    \u001b[0mn_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m    \u001b[0mn2_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1.0 is bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
          ]
        }
      ]
    }
  ]
}